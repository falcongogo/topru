import streamlit as st
import numpy as np
from typing import Dict, Any
import tempfile
import os
import cv2
from PIL import Image
import config
from image_processor import ScoreImageProcessor

def process_uploaded_image(uploaded_file, shear_method: str, manual_angle: float) -> Dict[str, Any]:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’å‡¦ç†ã—ã¦ç‚¹æ•°ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¿”ã™"""
    if 'image_processor' not in st.session_state or st.session_state.image_processor is None:
        try:
            st.session_state.image_processor = ScoreImageProcessor()
        except Exception as e:
            return {'status': 'error', 'message': f"ç”»åƒå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}

    try:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        if image is None:
            raise ValueError("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")

        scores = st.session_state.image_processor.process_score_image(
            image, shear_correction_method=shear_method, manual_shear_angle=manual_angle
        )

        if not scores:
            return {'status': 'warning', 'message': "ç‚¹æ•°ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ç”»åƒã®è§’åº¦ã‚„æ˜ã‚‹ã•ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}

        return {'status': 'success', 'scores': scores, 'message': f"ç‚¹æ•°ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸ: {scores}"}

    except Exception as e:
        return {'status': 'error', 'message': f"ç”»åƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"}

def process_uploaded_image_full_debug(uploaded_file, shear_method: str, manual_angle: float):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’å‡¦ç†ã—ã¦è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å–å¾—"""
    if 'image_processor' not in st.session_state or st.session_state.image_processor is None:
        try:
            st.session_state.image_processor = ScoreImageProcessor()
        except Exception as e:
            st.error(f"ç”»åƒå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None

    try:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        if image is None:
            raise ValueError("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")

        return st.session_state.image_processor.get_full_debug_bundle(
            image, shear_correction_method=shear_method, manual_shear_angle=manual_angle
        )

    except Exception as e:
        st.error(f"ãƒ‡ãƒãƒƒã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

def render_image_upload_section() -> Dict[str, int]:
    """ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æç”»"""
    st.subheader('ğŸ“· ã‚¹ãƒªãƒ ã‚¹ã‚³ã‚¢28Sç”»åƒã‹ã‚‰è‡ªå‹•å…¥åŠ›')

    # Initialize session state keys
    if 'last_uploaded_file_id' not in st.session_state:
        st.session_state.last_uploaded_file_id = None
    if 'ocr_status' not in st.session_state:
        st.session_state.ocr_status = None

    # Display OCR status from previous run
    if st.session_state.ocr_status:
        status = st.session_state.ocr_status
        if status['status'] == 'success':
            st.success(status['message'])
        elif status['status'] == 'warning':
            st.warning(status['message'])
        elif status['status'] == 'error':
            st.error(status['message'])

    uploaded_file = st.file_uploader(
        "ã‚¹ãƒªãƒ ã‚¹ã‚³ã‚¢28Sã®ç‚¹æ•°è¡¨ç¤ºç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['png', 'jpg', 'jpeg'],
        help="ã‚¹ãƒãƒ›ã§æ’®å½±ã—ãŸã‚¹ãƒªãƒ ã‚¹ã‚³ã‚¢28Sã®ç‚¹æ•°è¡¨ç¤ºç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«ç‚¹æ•°ã‚’èª­ã¿å–ã‚Šã¾ã™"
    )

    st.markdown("##### ç”»åƒè£œæ­£è¨­å®š")
    method_options = {
        'Houghå¤‰æ›': 'hough',
        'ä¸‹2æ¡ã®"00"ã‚’åˆ©ç”¨': 'zeros',
        'è§’åº¦ã‚’æ‰‹å‹•å…¥åŠ›': 'manual',
        'è£œæ­£ãªã—': 'none'
    }
    method_display = st.selectbox(
        "ã›ã‚“æ–­è£œæ­£ï¼ˆå‚¾ãè£œæ­£ï¼‰ã®æ–¹æ³•",
        options=list(method_options.keys()),
        index=1
    )
    shear_method = method_options[method_display]

    manual_angle = 0.0
    if shear_method == 'manual':
        manual_angle = st.number_input(
            "è£œæ­£è§’åº¦ï¼ˆÂ°ï¼‰",
            min_value=-45.0,
            max_value=45.0,
            value=9.0,
            step=0.1,
            help="ç”»åƒã®å‚¾ãè§’åº¦ã‚’åº¦æ•°ã§å…¥åŠ›ã—ã¾ã™ã€‚å³ã«å‚¾ã„ã¦ã„ã‚‹å ´åˆã¯æ­£ã®å€¤ã‚’å…¥åŠ›ã—ã¾ã™ã€‚"
        )

    if uploaded_file is not None:
        current_config_id = f"{uploaded_file.file_id}-{shear_method}-{manual_angle}"
        last_config_id = st.session_state.get('last_uploaded_file_id')

        # Reprocess if the file or any setting has changed
        if current_config_id != last_config_id:
            uploaded_file.seek(0)
            with st.spinner('ç”»åƒã‚’å‡¦ç†ä¸­...'):
                result = process_uploaded_image(uploaded_file, shear_method, manual_angle)
            st.session_state.ocr_status = result
            if result['status'] == 'success':
                st.session_state.scores = result['scores']

            # Invalidate the old debug bundle as config has changed
            if 'debug_bundle' in st.session_state:
                del st.session_state['debug_bundle']

            st.session_state.last_uploaded_file_id = current_config_id

        st.image(uploaded_file, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", width=300)

        debug_mode = st.checkbox('ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¤œå‡ºé ˜åŸŸã‚’è¡¨ç¤ºï¼‰', value=True)

        if debug_mode:
            st.markdown("---")
            st.subheader("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ±")

            # Regenerate debug bundle if it doesn't exist (it was deleted on config change)
            if 'debug_bundle' not in st.session_state:
                uploaded_file.seek(0)
                with st.spinner('è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ç”Ÿæˆä¸­...'):
                    st.session_state.debug_bundle = process_uploaded_image_full_debug(uploaded_file, shear_method, manual_angle)

            debug_bundle = st.session_state.get('debug_bundle')
            if debug_bundle:
                if 'warped_screen' in debug_bundle:
                    st.image(debug_bundle['warped_screen'], caption="1. ã‚¹ã‚¯ãƒªãƒ¼ãƒ³é ˜åŸŸã®åˆ‡ã‚Šå‡ºã—", use_container_width=True, channels="BGR")
                if 'shear_corrected_screen' in debug_bundle:
                    angle = debug_bundle.get('shear_angles', {}).get('screen', 0)
                    st.markdown(f"##### 2. ã›ã‚“æ–­è£œæ­£å¾Œã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ (è£œæ­£è§’åº¦: {angle:.2f}Â°)")
                    st.image(debug_bundle['shear_corrected_screen'], caption="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³å…¨ä½“ã«ã›ã‚“æ–­è£œæ­£ã‚’é©ç”¨", use_container_width=True)
                if 'deskewed_digits' in debug_bundle and debug_bundle['deskewed_digits']:
                    st.markdown("##### 3. æœ€çµ‚çš„ãªåˆ‡ã‚Šå‡ºã—æ•°å­—")
                    for player, digits in debug_bundle['deskewed_digits'].items():
                        st.write(f"**{player}**")
                        if not digits:
                            st.write("ï¼ˆæ•°å­—ã®åˆ‡ã‚Šå‡ºã—ã«å¤±æ•—ï¼‰")
                            continue
                        pil_images = [Image.fromarray(d) for d in digits if d is not None and d.size > 0]
                        if pil_images:
                            widths, heights = zip(*(i.size for i in pil_images))
                            total_width = sum(widths)
                            max_height = max(heights)
                            concatenated_image = Image.new('L', (total_width, max_height))
                            x_offset = 0
                            for im in pil_images:
                                concatenated_image.paste(im, (x_offset,0))
                                x_offset += im.size[0]
                            st.image(concatenated_image, caption=f"{player} åˆ‡ã‚Šå‡ºã—å¾Œ", use_container_width=True)

    return st.session_state.get('scores', {})

def render_score_inputs() -> Dict[str, int]:
    """ç‚¹æ•°å…¥åŠ›UIã®æç”»"""
    st.subheader('ç‚¹æ•°å…¥åŠ›ï¼ˆç™¾ç‚¹å˜ä½ï¼‰')
    image_scores = render_image_upload_section()

    st.markdown("---")
    st.markdown("**æ‰‹å‹•å…¥åŠ›**")
    cols = st.columns(4)
    scores = {}

    for i, player in enumerate(config.PLAYERS):
        with cols[i]:
            default = (image_scores.get(player) or st.session_state.scores.get(player, 0)) // 100
            value = st.number_input(
                f'{player} ã®ç‚¹æ•°',
                min_value=0,
                max_value=999,
                step=1,
                value=default,
                key=f'score_{player}'
            )
            scores[player] = value * 100

    return scores

def get_condition_style(result: Dict[str, Any]) -> tuple[str, str, str]:
    """æ¡ä»¶ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã‚’è¿”ã™"""
    rank = result['rank']
    is_direct = result.get('is_direct', False)

    if rank == 'ä¸å¯èƒ½':
        return '#ffd6d6', "âŒ", ""
    elif rank.startswith('æº€è²«'):
        return '#ffe566', "ğŸŒŸ", "bold"
    elif any(x in rank for x in ['è·³æº€', 'å€æº€', 'ä¸‰å€æº€', 'å½¹æº€']):
        return '#ffd700', "ğŸ’", "bold"
    elif is_direct:
        return '#e0f7fa', "ç›´æ’ƒ", "bold"
    else:
        return '#fff6e6', "", ""

def render_condition_card(result: Dict[str, Any]) -> None:
    """æ¡ä»¶ã‚«ãƒ¼ãƒ‰ã‚’æç”»"""
    bgcolor, badge, weight_class = get_condition_style(result)

    total_info = ""
    if 'total_points' in result and 'opponent_loss' in result and 'difference_points' in result:
        total_info = f"<div class='details'>åˆè¨ˆ: {result['total_points']} / ç›¸æ‰‹: {result['opponent_loss']} / å·®åˆ†: {result['difference_points']}</div>"

    st.markdown(f"""
    <div class='condition-card' style='background:{bgcolor};'>
        <span class='title {weight_class}'>{badge} {result['æ¡ä»¶']}</span><br>
        <span class='rank {weight_class}'>{result['rank']}ï¼ˆ{result['display']}ï¼‰</span>
        {total_info}
    </div>
    """, unsafe_allow_html=True)

def display_top_difference(top_diff: int, leader: str) -> None:
    """ãƒˆãƒƒãƒ—ã¨ã®å·®ã‚’è¡¨ç¤º"""
    if top_diff <= 0:
        st.success("ã‚ãªãŸã¯ç¾åœ¨ãƒˆãƒƒãƒ—ã§ã™ï¼")
    else:
        if top_diff >= config.TOP_DIFF_COLOR_THRESHOLDS['red']:
            color = 'red'
        elif top_diff >= config.TOP_DIFF_COLOR_THRESHOLDS['orange']:
            color = 'orange'
        else:
            color = 'green'

        st.markdown(f"""
        <h2 style='color:{color};'>
            TOPã¨ã®å·®ï¼š<span class='top-diff-leader'>{top_diff} ç‚¹</span>ï¼ˆãƒˆãƒƒãƒ—: {leader}ï¼‰
        </h2>
        """, unsafe_allow_html=True)

def validate_inputs(scores: Dict[str, int], tsumibo: int, kyotaku: int) -> bool:
    """å…¥åŠ›å€¤ã®æ¤œè¨¼"""
    if any(score < 0 for score in scores.values()):
        st.error("ç‚¹æ•°ã¯0ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return False
    if tsumibo < 0 or kyotaku < 0:
        st.error("ç©ã¿æ£’ãƒ»ä¾›è¨—æ£’ã¯0ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return False
    return True
